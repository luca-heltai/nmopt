# Introduction and Motivation for PDE-Constrained Optimal Control

```{admonition} Slides for this lecture
:class: tip

[Open slides](/slideshow/slides01.html)
```

## Overview

This lecture introduces optimal control as an optimization problem constrained by equations.
We first build the finite-dimensional analogy, then move to PDE-constrained models.

Logical path of the lecture:

1. start from a constrained optimization problem in $(y,u)$;
2. eliminate the state through the model equation when possible;
3. obtain a reduced optimization problem in the control variable only;
4. derive first-order conditions in finite dimension;
5. transfer the same structure to PDE settings.

---

## 1. General Optimal Control Problem

Choose a control variable $u$ and a state variable $y$ such that
$$
(y^\star,u^\star)\in\operatorname*{argmin}_{(y,u)} J(y,u)
$$
subject to
$$
\mathcal{E}(y,u)=0,\qquad u\in\mathcal{U}_{\mathrm{ad}}.
$$

Key ingredients:

- state equation $\mathcal{E}(y,u)=0$ (ODE/PDE/algebraic)
- admissible controls $u\in\mathcal{U}_{\mathrm{ad}}$
- cost functional $J(y,u)$
- optional extra constraints (box constraints, state constraints, etc.)

---

## 2. Forward Problem vs Control Problem

Forward problem:

- data are fixed
- solve once for $y$

Optimal control:

- $u$ is unknown
- solve the state equation repeatedly inside optimization

```{admonition} Key point
:class: important

In optimal control, the PDE is a constraint, not the objective.
```

---

## 3. Finite-Dimensional Setting (Simultaneous vs Reduced)

Consider
$$
\min_{y\in\mathbb{R}^n,\,u\in\mathbb{R}^m} J(y,u)
\quad\text{s.t.}\quad Ay=Bu,
$$
with $A\in\mathbb{R}^{n\times n}$ invertible.

### 3.1 Simultaneous formulation

Optimize in $(y,u)$ and enforce $Ay=Bu$ explicitly.

Interpretation:

- optimization variable: the pair $(y,u)$;
- coupling: $y$ and $u$ are linked by the model equation;
- computational consequence: every candidate pair must satisfy the constraint.

### 3.2 Reduced formulation

Since $A$ is invertible,
$$
y=A^{-1}Bu=:S(u),
$$
where $S$ is the control-to-state operator.
Then define
$$
f(u):=J(S(u),u),
$$
and solve
$$
\min_{u\in\mathcal{U}_{\mathrm{ad}}} f(u).
$$

This reduces a finite-dimensional control problem to a standard finite-dimensional optimization problem.

Step-by-step logic:

1. the constraint $Ay=Bu$ defines $y$ uniquely as a function of $u$;
2. therefore the only independent decision variable is $u$;
3. the objective becomes a composite map $u\mapsto J(S(u),u)$;
4. all constraint information is encoded in $S$.

---

## 4. Existence in Finite Dimensions

A standard existence result for the reduced problem:

If

- $f$ is lower semicontinuous and bounded from below,
- one level set $L_t:=\{u\in\mathcal{U}_{\mathrm{ad}}:f(u)\le t\}$ is nonempty, closed, and bounded,

then a minimizer exists.

Reason: in finite dimensions, closed and bounded sets are compact (Weierstrass theorem).

Why this matters for control:

- before deriving optimality conditions, we need existence of at least one minimizer;
- existence is easy in finite dimension under compactness of level sets;
- this argument will fail in infinite dimensions unless additional structure is used.

```{admonition} Important warning
:class: note

In infinite-dimensional spaces, closed and bounded sets are generally not compact.
This is one of the main analytical difficulties for PDE-constrained optimization.
```

---

## 5. Unconstrained First/Second-Order Conditions

For convex differentiable $f$ on a convex set $K$:
$$
\nabla f(\bar u)\cdot (u-\bar u)\ge 0\quad\forall u\in K
$$
is the first-order optimality condition.

Special case (interior point):
$$
\nabla f(\bar u)=0.
$$

If $f\in C^2$ and $\bar u$ is a local minimizer:

- $\nabla f(\bar u)=0$
- $D^2 f(\bar u)$ is positive semidefinite

If moreover $D^2 f(\bar u)$ is positive definite, then $\bar u$ is a strict local minimizer.

---

## 6. Constrained minimization (2D Example)

Let
$$
\mathcal{U}_{\mathrm{ad}}=\mathbb{R}^2,\qquad
f(u)=\frac12 u^T A u,\qquad
\varphi(u)=Bu-g=0,
$$
with
$$
A\in\mathbb{R}^{2\times 2}\text{ SPD},\quad B\in\mathbb{R}^{1\times 2},\quad g\in\mathbb{R}.
$$

Logical interpretation:

1. objective level sets are ellipses (because $A$ is SPD);
2. feasible points lie on an affine line $Bu-g=0$;
3. the minimizer is where the first objective level set touches that feasible line.

At an optimal feasible point, $\nabla f$ is orthogonal to the feasible tangent direction,
so it must be parallel to $\nabla\varphi$:
$$
\nabla f(\bar u)=(\nabla\varphi(\bar u))^T\lambda.
$$

Equivalent first-order form:
$$
\nabla f(\bar u)-(\nabla\varphi(\bar u))^T\lambda=0,
\qquad
\varphi(\bar u)=0.
$$

Meaning:

- $\varphi(\bar u)=0$: feasibility at the solution;
- gradient balance: objective gradient is compensated by constraint normal direction;
- multiplier $\lambda$: strength/sign of that compensation.

### Lagrangian Formalism

Define the Lagrangian
$$
\mathcal{L}(u,\lambda)=f(u)-\varphi(u)\cdot\lambda.
$$
and search for saddle points:
$$
\bar u, \bar\lambda = \arg\min_u \arg\max_\lambda \mathcal{L}(u,\lambda).
$$

Stationarity gives
$$
\frac{\partial\mathcal{L}}{\partial u}=0,
\qquad
\frac{\partial\mathcal{L}}{\partial \lambda}=0.
$$

For this quadratic/affine case:
$$
\nabla_u\mathcal{L}=Au-B^T\lambda=0,
\qquad
\nabla_\lambda\mathcal{L}=-Bu+g=0,
$$
which is the KKT linear system
$$ \begin{pmatrix}A & -B^T \\\ -B & 0\end{pmatrix}\begin{pmatrix}u \\\ \lambda\end{pmatrix}=\begin{pmatrix}0 \\\ -g\end{pmatrix}. $$

This is the prototype for all later optimality systems:

- state/constraint equation;
- adjoint or multiplier equation;
- coupling through stationarity.

<div style="display: flex; gap: 10px;">
<img src="../slides/assets/01_minimization_geometry.png" alt="Geometry of the 2D minimization example" style="width: 50%;">
<img src="../slides/assets/01_minimization_on_constraint.png" alt="Objective restricted to the feasible line" style="width: 50%;">
</div>

---

## 7. From Finite to Infinite Dimensions

For PDE-constrained control, state/control live in function spaces (typically Hilbert spaces):

- state space $Y$ (e.g. Sobolev spaces)
- control space $U$
- PDE operator $\mathcal{E}(y,u)=0$

Typical difficulties:

- non-compactness in infinite dimension
- weak vs strong convergence issues
- differentiability in Banach/Hilbert spaces
- adjoint equations for gradient computation

Conceptual continuity with the finite-dimensional case:

1. same optimization structure;
2. same reduced-vs-simultaneous viewpoints;
3. same KKT logic;
4. only the functional-analytic setting changes.

---

## 8. Prototypical PDE-Constrained Models

### 8.1 Elliptic distributed control

$$
\min_{(y,u)}
\frac12\|y-y_d\|_{L^2(\Omega)}^2
+\frac\alpha2\|u\|_{L^2(\Omega)}^2
$$
subject to
$$
-\Delta y=u\text{ in }\Omega,
\qquad y=0\text{ on }\partial\Omega,
\qquad u\in U_{\mathrm{ad}}.
$$

### 8.2 Parabolic control

$$
\partial_t y-\Delta y=u\text{ in }Q,
\qquad y(\cdot,0)=y_0,
$$
with tracking over space-time and Tikhonov regularization.

### 8.3 Flow and inverse problems

- Navier-Stokes control (nonlinear constraints)
- parameter estimation/data assimilation

---

## 9. Control Constraints

Common box constraints:
$$
u_{\min}\le u\le u_{\max}.
$$

They lead to variational inequalities and KKT systems in function spaces.

---

## 10. Typical Variations of OCP Formulations

Many optimal control models keep the same abstract structure but vary in where the control acts, what is observed, and how the objective is measured.

Common variations include:

- **Localized distributed control**: $u$ acts only on a subdomain $\omega\subset\Omega$ (for example through $\chi_\omega u$ in the PDE).
- **Boundary control**: $u$ appears in Dirichlet/Neumann/Robin boundary conditions on part of $\partial\Omega$.
- **Initial-condition control**: $u$ is an unknown initial datum in time-dependent models.
- **Parameter control**: $u$ is a coefficient (diffusivity, reaction rate, material parameter), not a source term.
- **Different tracking norms**: replace $L^2$ tracking by $H^1$, weighted norms, or mixed space-time norms.
- **Different control penalties**: use $L^2$, $H^1$, or sparsity-promoting terms (e.g. $L^1$-type penalties).
- **Pointwise state constraints**: enforce bounds on the state (or output) in the domain or on the boundary.
- **Multi-objective costs**: combine tracking, regularization, and engineering criteria (energy, drag, flux, etc.).
- **Inverse problems / data assimilation**: identify unknown inputs/parameters from measurements with regularization.
- **Uncertainty-aware OCPs**: optimize expected cost, risk measures, or robust worst-case criteria.

These variants motivate why we need a flexible theoretical framework and multiple numerical methods in the rest of the course.

---

## References for This Lecture

- F. TrÃ¶ltzsch, *Optimal Control of Partial Differential Equations*, Chapter 1
- A. Manzoni, A. Quarteroni, S. Salsa, *Optimal Control of PDEs*, Chapter 1
- J. C. De los Reyes, *Numerical PDE-Constrained Optimization*, Section 1

<!-- FOOTER START -->
<iframe src="/nmopt/slideshow/slides01.html" width="100%" height="800px" style="border: none;"></iframe>

---

```{admonition} ðŸŽ¬ View Slides
:class: tip

**[Open slides in full screen](/nmopt/slideshow/slides01.html)** for the best viewing experience.
```
<!-- FOOTER END -->
